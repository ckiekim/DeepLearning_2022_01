{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "31.GAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4bgoCUp5Vnu"
      },
      "source": [
        "- 내용 및 코드 참조 \n",
        "\n",
        "  - 케라스 창시자로부터 배우는 딥러닝\n",
        "\n",
        "  - 미술관에 GAN 딥러닝 실전 프로젝트 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeLTZPP-sQ5x"
      },
      "source": [
        "# 적대적 생성 신경망(Generative Adversarial Networks, GAN)\n",
        "\n",
        "- 2014년, Ian Goodfellow 소개\n",
        "\n",
        "- VAE(Variation AutoEncoder)와는 다른 방법으로 이미지 잠재 공간을 학습\n",
        "\n",
        "- 직관적으로 이해하는 방법\n",
        "\n",
        "  - 가짜 피카소 그림을 그리는 위조범과 이를 판별하는 판매상의 관계\n",
        "\n",
        "  - 위조품과 진짜 그림을 섞어서 판매상에게 보여주며  \n",
        "    그림이 진짜인지 가짜인지 판매상은 판별하고 이를 위조범에게 피드백\n",
        "\n",
        "  - 처음에는 형편없는 그림을 그리다가 점점 피카소의 스타일을 모방하게 되고  \n",
        "    판매상은 위조품을 구분하는데 점점 더 전문가가 되어감\n",
        "\n",
        "- GAN의 네트워크\n",
        "\n",
        "  - 생성자 네트워크(generator network)\n",
        "\n",
        "    - 랜덤 벡터(잠재 공간의 무작위한 포인트)를 입력으로 받아 이를 합성된 이미지로 디코딩\n",
        "\n",
        "  - 판별자 네트워크(discriminator network)\n",
        "\n",
        "    - 이미지(실제 또는 가짜 이미지)를 입력으로 받아 훈련 세트에서 온 이미지인지 생성자가 만든 이미지인지 판별\n",
        "\n",
        "- GAN은 최적화의 최솟값이 고정되어 있지 않음\n",
        "\n",
        "  - 보통의 경사하강법은 **고정된 손실공간**에서 언덕을 내려오는 훈련 방법이지만  \n",
        "    GAN은 매 단계가 조금씩 전체 공간을 바꾸기 때문에 최적화 과정이 최솟값을 찾는 것이 어려움\n",
        "\n",
        "  - 두 힘간의 평형점을 찾는 시스템\n",
        "\n",
        "  - 따라서, 학습과정이 매우 어려움  \n",
        "    즉, 적절한 파라미터를 찾고 조정해야함\n",
        "  \n",
        "  <img src=\"https://paperswithcode.com/media/methods/gan.jpeg\">\n",
        "\n",
        "  <sub>[이미지 출처] https://paperswithcode.com/method/gan</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHhtFZ1huWoB"
      },
      "source": [
        "## GAN의 구현 (DCGAN: Deep Convolutional Generative Adversarial Networks)\n",
        "\n",
        "- CIFAR-10 데이터셋 사용\n",
        "\n",
        "- generator 네트워크는 (latent_dim,) 크기의 벡터를 (32, 32, 3) 크기의 이미지로 매핑\n",
        "\n",
        "- discriminator 네트워크는 (32, 32, 3) 크기의 이미지가 진짜일 확률을 추정하여 이진값으로 매핑\n",
        "\n",
        "- 생성자와 판별자를 연결하는 gan 네트워크를 만듬  \n",
        "  \n",
        "  - gan(x) = discriminator(generator(x))\n",
        "\n",
        "- 진짜/가짜 레이블과 함께 진짜 이미지와 가짜 이미지 샘플을 사용하여 판별자를 훈련 (일반적인 이미지 분류 모델 훈련과 동일)\n",
        "\n",
        "- 생성자를 훈련하려면 gan 모델의 손실에 대한 생성자 가중치의 그래디언트를 사용\n",
        "\n",
        "  - 매 단계마다 생성자에 의해 디코딩된 이미지를 판별자가 \"진짜\"로 분류하도록 만드는 방향으로 생성자의 가중치를 이동\n",
        "\n",
        "  - 판별자를 속이도록 생성자를 훈련한다는 말\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rb4JHajh1gXx"
      },
      "source": [
        "## 학습 방법\n",
        "\n",
        "- 마지막 활성화 함수로 sigmoid 대신 tanh함수 사용\n",
        "\n",
        "- 균등분포가 아니고 정규 분포(가우시안 분포)를 사용하여 잠재 공간에서 포인트를 샘플링\n",
        "\n",
        "- 무작위성을 주입\n",
        "\n",
        "  - 판별자에 드롭아웃을 사용\n",
        "\n",
        "  - 판별자를 위해 레이블에 랜덤 노이즈를 추가\n",
        "\n",
        "- 희소한 그래디언트는 GAN 훈련에 방해가 될 수 있음\n",
        "\n",
        "  - 최대 풀링 대신 스트라이드 합성곱을 사용하여 다운샘플링\n",
        "\n",
        "  - ReLU 대신 LeakyReLU 사용\n",
        "\n",
        "- 생성자에서 픽셀 공간을 균일하게 다루지 못하여 생성된 이미지에서 체스판 모양이 종종 나타남.  \n",
        "  이를 위해 생성자와 판별자에서 스트라이드 Conv2DTranspose나 Conv2D를 사용할 때 스트라이드 크기로 나누어 질 수 있는 커널 크기 사용\n",
        "\n",
        "  - 커널 크기가 스트라이드의 배수가 아니면 픽셀이 공평하게 합성곱 되지 않음  \n",
        "    커널 크기를 스트라이드로 나누었을 때 나머지 크기에 해당하는 픽셀이 더 많이 업샘플링에 참여하게 됨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiIV25ew2SDq"
      },
      "source": [
        "### GAN 생성자 네트워크\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-y52HdbXSkq"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, LeakyReLU, Reshape, Conv2D\n",
        "from tensorflow.keras.layers import Conv2DTranspose, Flatten, Dropout\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkWJCAGF2o0r"
      },
      "source": [
        "latent_dim = 32\n",
        "height, width, channels = 32, 32, 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVp1CdYG2tu0"
      },
      "source": [
        "generator_input = Input(shape=(latent_dim,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI2bVCCz2wgh"
      },
      "source": [
        "x = Dense(128 * 16 * 16)(generator_input)\n",
        "x = LeakyReLU()(x)\n",
        "x = Reshape((16, 16, 128))(x)\n",
        "\n",
        "x = Conv2D(256, 5, padding='same')(x)\n",
        "x = LeakyReLU()(x)\n",
        "\n",
        "x = Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
        "x = LeakyReLU()(x)\n",
        "\n",
        "x = Conv2D(256, 5, padding='same')(x)\n",
        "x = LeakyReLU()(x)\n",
        "x = Conv2D(256, 5, padding='same')(x)\n",
        "x = LeakyReLU()(x)\n",
        "\n",
        "x = Conv2D(channels, 7, activation='tanh', padding='same')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = Model(generator_input, x)\n",
        "generator.summary()"
      ],
      "metadata": {
        "id": "wovZ-4oz2Ehb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnRjKuGy3By9"
      },
      "source": [
        "### GAN 판별자 네트워크\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0rd_EYq3Epn"
      },
      "source": [
        "discriminator_input = Input(shape=(height, width, channels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcJ8iXrO3BXO"
      },
      "source": [
        "x = Conv2D(128, 3)(discriminator_input)\n",
        "x = LeakyReLU()(x)\n",
        "x = Conv2D(128, 4, strides=2)(x)\n",
        "x = LeakyReLU()(x)\n",
        "x = Conv2D(128, 4, strides=2)(x)\n",
        "x = LeakyReLU()(x)\n",
        "x = Conv2D(128, 4, strides=2)(x)\n",
        "x = LeakyReLU()(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(1, activation='sigmoid')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = Model(discriminator_input, x)\n",
        "discriminator.summary()"
      ],
      "metadata": {
        "id": "MiByLWVh2Hxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQuMOoH_3WbY"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3zZbyx13TGi"
      },
      "source": [
        "discriminator_optimizer = RMSprop(learning_rate=0.0008, clipvalue=1.0, decay=1e-8)\n",
        "discriminator.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayIotK_Q3iE7"
      },
      "source": [
        "### 적대적 네트워크\n",
        "- 생성자와 판별자를 연결\n",
        "\n",
        "- 훈련할 때 생성자가 판별자를 속이는 능력이 커지도록 학습\n",
        "\n",
        "- 잠재 공간의 포인트를 진짜 또는 가짜의 분류 결정으로 변환\n",
        "\n",
        "- 훈련에 사용되는 target label은 항상 \"진짜 이미지\"\n",
        "\n",
        "- 훈련하는 동안 판별자를 동결(학습되지 않도록)하는 것이 매우 중요!\n",
        "\n",
        "  - 판별자의 가중치가 훈련하는 동안 업데이트되면 판별자는 항상 진짜를 예측하도록 훈련됨"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eerQWi8_3auo"
      },
      "source": [
        "discriminator.trainable = False\n",
        "\n",
        "gan_input = Input(shape=(latent_dim,))\n",
        "gan_output = discriminator(generator(gan_input))\n",
        "gan = Model(gan_input, gan_output)\n",
        "\n",
        "gan_optimizer = RMSprop(learning_rate=0.0004, clipvalue=1.0, decay=1e-8)\n",
        "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gan.summary()"
      ],
      "metadata": {
        "id": "07JdYkoq2NW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oP5cjQs74G5Q"
      },
      "source": [
        "### GAN 훈련 구현\n",
        "\n",
        "- DCGAN 구현\n",
        "\n",
        "- 매 반복마다 아래의 과정 수행\n",
        "\n",
        "  1. 잠재 공간에서 무작위로 포인트를 뽑음(랜덤 노이즈)\n",
        "\n",
        "  2. 랜덤 노이즈를 사용하여 generator에서 이미지를 생성\n",
        "\n",
        "  3. 생성된 이미지와 진짜 이미지를 섞음\n",
        "\n",
        "  4. 진짜와 가짜가 섞인 이미지와 이에 대응하는 타깃을 사용하여 discriminator를 훈련  \n",
        "    타킷은 진짜 또는 가짜\n",
        "\n",
        "  5. 잠재 공간에서 무작위로 새로운 포인트를 뽑음\n",
        "\n",
        "  6. 랜덤 벡터를 사용하여 gan을 훈련.  \n",
        "    모든 타깃은 진짜로 설정. \n",
        "    - 판별자가 생성된 이미지를 모두 \"진짜 이미지\"라고 예측하도록 생성자의 가중치를 업데이트.  \n",
        "      (판별자는 동결되기 때문에 생성자만 업데이트)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GimAaUDC4u-P"
      },
      "source": [
        "import os\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing import image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLrdG7a84yFE"
      },
      "source": [
        "#### CIFAR10 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siDPaZ-J3nSk"
      },
      "source": [
        "(X_train, y_train), (_, _) = cifar10.load_data()\n",
        "X_train.shape, y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgzNpE6O4-ik"
      },
      "source": [
        "#### 개구리 이미지를 선택"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBF8XEbj41ZU"
      },
      "source": [
        "X_train = X_train[y_train.flatten() == 6]\n",
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be7fKh6-5BMn"
      },
      "source": [
        "#### 데이터 정규화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b12T22Sh5FQa"
      },
      "source": [
        "X_train = X_train.astype('float32') / 255.\n",
        "type(X_train[0,0,0,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iterations = 10000\n",
        "batch_size = 20\n",
        "\n",
        "save_dir = 'gan_images'\n",
        "if not os.path.exists(save_dir):\n",
        "    os.mkdir(save_dir)"
      ],
      "metadata": {
        "id": "A0mVnALctuNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIfCHuXQ7HOJ"
      },
      "source": [
        "#### 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puOujZ3F5D2f"
      },
      "source": [
        "start = 0\n",
        "for step in range(iterations):\n",
        "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
        "    generated_images = generator.predict(random_latent_vectors)\n",
        "\n",
        "    stop = start + batch_size\n",
        "    real_images = X_train[start:stop]\n",
        "    combined_images = np.concatenate([generated_images, real_images])\n",
        "\n",
        "    labels = np.concatenate([np.ones((batch_size,1)), np.zeros((batch_size,1))])\n",
        "    labels += 0.05 * np.random.random(labels.shape)\n",
        "\n",
        "    d_loss = discriminator.train_on_batch(combined_images, labels)\n",
        "\n",
        "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
        "    misleading_targets = np.zeros((batch_size, 1))\n",
        "\n",
        "    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
        "\n",
        "    start += batch_size\n",
        "    if start > len(X_train) - batch_size:\n",
        "        start = 0\n",
        "    \n",
        "    if step % 100 == 0:\n",
        "        print(f'Step: {step}, discriminator loss: {d_loss:.4f}, adversarial loss: {a_loss:.4f}')\n",
        "        gan.save_weights('gan.h5')\n",
        "        img = image.array_to_img(generated_images[0] * 255, scale=False)\n",
        "        img.save(os.path.join(save_dir, f'generated_frog_{step}.png'))\n",
        "        img = image.array_to_img(real_images[0] * 255, scale=False)\n",
        "        img.save(os.path.join(save_dir, f'real_frog_{step}.png'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I4J9HSI7Kco"
      },
      "source": [
        "#### 이미지 생성을 통한 시각화\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9r2Bfwk5iNf"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KS9f7FGO7ijf"
      },
      "source": [
        "- 잠재 공간에서 랜덤한 포인트를 샘플링\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6zPuYw97EHk"
      },
      "source": [
        "random_latent_vectors = np.random.normal(size=(10, latent_dim))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IikNB0zM7lQ8"
      },
      "source": [
        "- 가짜 이미지로 디코딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHSY6hNU7AlE"
      },
      "source": [
        "generated_images = generator.predict(random_latent_vectors)\n",
        "generated_images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gyn_d90--r0"
      },
      "source": [
        "plt.figure(figsize=(5,2))\n",
        "for i in range(generated_images.shape[0]):\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    img = image.array_to_img(generated_images[i] * 255, scale=False)\n",
        "    plt.imshow(img)\n",
        "    plt.xticks([]), plt.yticks([])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip images.zip gan_images/*"
      ],
      "metadata": {
        "id": "LKbawPXr3XNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BwocriqA4tWG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}